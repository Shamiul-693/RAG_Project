
# Bengali PDF-based RAG QA System

This project implements a simple Bengali Retrieval-Augmented Generation (RAG) pipeline using OCR, vector search (FAISS), and a local LLM (Ollama with Mistral) to answer questions from scanned Bangla PDFs.

---

## âœ… Setup Guide

1. Clone the repository:

```bash
git clone https://github.com/Shamiul-693/RAG_Project.git
cd rag_project
```

2. Create and activate virtual environment:

```bash
python -m venv venv
venv\Scripts\activate.bat
```

3. Install requirements:

```bash
pip install -r requirements.txt
```

4. Install Poppler (required for pdf2image):

- Download from: [https://github.com/oschwartz10612/poppler-windows/releases/](https://github.com/oschwartz10612/poppler-windows/releases/)
- Extract to a folder, e.g. `C:\poppler`
- Add `C:\poppler\Library\bin` to your system PATH

5. Install Tesseract OCR:

- Download from: [https://github.com/tesseract-ocr/tesseract](https://github.com/tesseract-ocr/tesseract)
- Add to PATH: `C:\Program Files\Tesseract-OCR\`
- Ensure `ben.traineddata` exists in `C:\Program Files\Tesseract-OCR\tessdata`

6. Install and run Ollama with mistral model:

```bash
ollama run mistral
```

---

## ğŸ§° Tools, Libraries, Packages Used

- Python 3.10+
- pytesseract (OCR)
- pdf2image
- sentence-transformers
- faiss-cpu
- ollama
- tqdm, re, nltk, numpy

---

## ğŸ’¡ Sample Queries and Output

- Query (Bangla): `à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?`
- Output (Bangla): `à§à¦®à§à¦­à¦¨à¦¾à¦¥ `

---

## ğŸ“¡ API Documentation 

If exposed via FastAPI:

```python
@app.post("/ask")
def ask_question(file: UploadFile, query: str):
    # Process PDF and run RAG
    return {"answer": "..." }
```

---

## ğŸ“Š Evaluation Matrix (optional)

| Metric           | Description                                    |
| ---------------- | ---------------------------------------------- |
| Top-k Accuracy   | If correct chunk is among top k retrieved      |
| BLEU/ROUGE Score | Comparing generated answer vs reference answer |
| Manual Check     | Human judgment for answer relevance            |

---

## ğŸ¤” Questions & Answers

1. ğŸ” What method/library did you use to extract the text and why?

   - Used pytesseract + pdf2image since the PDF is scanned.
   - Challenge: OCR quality may vary with noise or poor layout.

2. âœ‚ï¸ What chunking strategy did you choose?

   - Sentence or paragraph-based chunks (\~400 chars).
   - Works well for semantic search and maintains context.

3. ğŸ§  What embedding model did you use and why?

   - `paraphrase-multilingual-MiniLM-L12-v2`
   - Lightweight, supports Bengali, good semantic matching.

4. ğŸ“Œ How are you comparing the query with chunks?

   - Used FAISS with cosine similarity.
   - Fast vector retrieval and scalable.

5. ğŸ” How do you ensure meaningful comparison?

   - Consistent preprocessing, same embedder for query + chunks.
   - Handles vague queries by increasing top-k or fallback keyword search.

6. âœ… Are results relevant?

   - Mostly yes.
   - Improvements: better chunking, OCR cleanup, embedding tuning.

---

## ğŸ“‚ Folder Structure

```
rag_project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ cleaner.py
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ generator.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ HSC26-Bangla1st-Paper.pdf
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---


